{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18089\\AppData\\Local\\Temp\\ipykernel_23444\\1518687564.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 构建改进后的CNN模型\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # 定义卷积层和批量归一化层\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 定义池化层\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # 全连接层\n",
    "        self.fc2 = nn.Linear(1024, 256)  # 全连接层\n",
    "        self.fc3 = nn.Linear(256, num_classes)  # 输出层，num_classes为类别数\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout层，用于防止过拟合\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # 第一个卷积层\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # 第二个卷积层\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # 第三个卷积层\n",
    "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))  # 第四个卷积层\n",
    "        x = x.view(-1, 512 * 14 * 14)  # 展平操作\n",
    "        x = torch.relu(self.fc1(x))  # 第一个全连接层\n",
    "        x = self.dropout(x)  # Dropout层\n",
    "        x = torch.relu(self.fc2(x))  # 第二个全连接层\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "\n",
    "# 判断文件是否有效\n",
    "def is_valid_file(filename):\n",
    "    # 过滤掉以点开头的文件（如隐藏文件）和 .DS_Store 文件\n",
    "    return not filename.startswith('.') and filename != '.DS_Store'\n",
    "\n",
    "\n",
    "# 预测函数\n",
    "def predict_images(model, image_dir, result_save_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 图片预处理（与训练时保持一致）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图片大小\n",
    "        transforms.ToTensor(),  # 转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "    ])\n",
    "\n",
    "    if not os.path.exists(image_dir):\n",
    "        print(f\"Error: Directory {image_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    image_files = [name for name in os.listdir(image_dir) if is_valid_file(name)]\n",
    "    res = ['img_name,label']  # 初始化结果文件，定义表头\n",
    "\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # 读取图片并转换为RGB格式\n",
    "        image = transform(image).unsqueeze(0).to(device)  # 预处理并转移到设备\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred_class = predicted.item()\n",
    "            res.append(f'{img_name},{pred_class}')\n",
    "\n",
    "    # 将预测结果保存到result_save_path\n",
    "    with open(result_save_path, 'w') as f:\n",
    "        f.write('\\n'.join(res))\n",
    "\n",
    "    # 使用 Pandas 交换列的位置\n",
    "    result_df = pd.read_csv(result_save_path)\n",
    "    result_df = result_df[['label', 'img_name']]  # 交换列的位置\n",
    "    result_df.to_csv(result_save_path, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 实例化模型并加载已保存的模型\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 动态选择使用 GPU 或 CPU\n",
    "    num_classes = 762  # 根据检查点的类别数进行修改\n",
    "    model = CNNModel(num_classes=num_classes).to(device)  # 创建模型实例\n",
    "\n",
    "    # 加载模型参数，允许部分加载\n",
    "    model_path = r'shetai\\my_pytorch_model.pth'\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "\n",
    "    # 要预测的图片文件夹路径\n",
    "    image_dir = r'last\\shetai\\image'\n",
    "    # 预测结果保存文件路径\n",
    "    result_save_path = r'last\\shetai\\jieguo.csv'\n",
    "\n",
    "    predict_images(model, image_dir, result_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18089\\AppData\\Local\\Temp\\ipykernel_23444\\1394969785.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(model_dir, 'my_pytorch_model.pth'), map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Work\\wen_jian\\中医药\\last\\shetai\\image\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 构建改进后的CNN模型\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # 定义卷积层和批量归一化层\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 定义池化层\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # 全连接层\n",
    "        self.fc2 = nn.Linear(1024, 256)  # 全连接层\n",
    "        self.fc3 = nn.Linear(256, num_classes)  # 输出层，num_classes为类别数\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout层，用于防止过拟合\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # 第一个卷积层\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # 第二个卷积层\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # 第三个卷积层\n",
    "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))  # 第四个卷积层\n",
    "        x = x.view(-1, 512 * 14 * 14)  # 展平操作\n",
    "        x = torch.relu(self.fc1(x))  # 第一个全连接层\n",
    "        x = self.dropout(x)  # Dropout层\n",
    "        x = torch.relu(self.fc2(x))  # 第二个全连接层\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "\n",
    "# 判断文件是否有效\n",
    "def is_valid_file(filename):\n",
    "    # 过滤掉以点开头的文件（如隐藏文件）和 .DS_Store 文件\n",
    "    return not filename.startswith('.') and filename != '.DS_Store'\n",
    "\n",
    "\n",
    "# 以下为逻辑函数, main函数的入参和最终的结果输出不可修改\n",
    "def main(to_pred_dir, result_save_path):\n",
    "    model_dir = r'shetai'\n",
    "\n",
    "    # 实例化模型并加载已保存的模型\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 动态选择使用 GPU 或 CPU\n",
    "    num_classes = 762  # 根据检查点的类别数进行修改\n",
    "    model = CNNModel(num_classes=num_classes).to(device)  # 创建模型实例\n",
    "\n",
    "    # 加载模型参数，允许部分加载\n",
    "    checkpoint = torch.load(os.path.join(model_dir, 'my_pytorch_model.pth'), map_location=device)\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "\n",
    "    # 图片预处理（与训练时保持一致）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图片大小\n",
    "        transforms.ToTensor(),  # 转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "    ])\n",
    "\n",
    "    if not os.path.exists(to_pred_dir):\n",
    "        print(f\"Error: Directory {to_pred_dir} does not exist.\")\n",
    "        return\n",
    "    print(to_pred_dir)\n",
    "    # 过滤掉非文件夹的内容\n",
    "    task_lst = [task for task in os.listdir(to_pred_dir) if os.path.isdir(os.path.join(to_pred_dir, task))]\n",
    "\n",
    "    res = ['img_name,label']  # 初始化结果文件，定义表头\n",
    "    for task_name in task_lst:  # 循环处理每个任务文件夹\n",
    "        print(task_name)\n",
    "        task_path = os.path.join(to_pred_dir, task_name)\n",
    "        support_path = os.path.join(task_path, 'support')  # 支持集路径（文件夹名即为标签）\n",
    "        query_path = os.path.join(task_path, 'query')  # 查询集路径（无标签，待预测图片）\n",
    "\n",
    "        if not os.path.exists(support_path) or not os.path.exists(query_path):\n",
    "            print(f\"Warning: Support or query path for {task_name} does not exist.\")\n",
    "            continue\n",
    "\n",
    "        prototypes = {}  # 存储各类别的原型向量\n",
    "        for class_name in os.listdir(support_path):  # 加载支持集并计算原型向量\n",
    "            if class_name == '.DS_Store':\n",
    "                continue\n",
    "            class_folder = os.path.join(support_path, class_name)\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "\n",
    "            class_features_list = []  # 存储当前类别的特征\n",
    "            for img_name in os.listdir(class_folder):  # 遍历每个类别中的图片\n",
    "                if img_name.startswith('.') or img_name == '.DS_Store':\n",
    "                    continue\n",
    "                img_path = os.path.join(class_folder, img_name)\n",
    "                image = Image.open(img_path).convert('RGB')  # 读取图片并转换为RGB格式\n",
    "                image = transform(image).unsqueeze(0).to(device)  # 预处理并转移到设备\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    features = model(image)  # 获取图片特征\n",
    "                    class_features_list.append(features)\n",
    "\n",
    "            if class_features_list:  # 计算该类别的原型向量（特征均值）\n",
    "                class_features = torch.cat(class_features_list, dim=0)\n",
    "                prototypes[class_name] = class_features.mean(dim=0)\n",
    "\n",
    "        # 预测查询集\n",
    "        test_img_lst = [name for name in os.listdir(query_path) if is_valid_file(name)]\n",
    "        for img_name in test_img_lst:  # 遍历查询集中的每张图片\n",
    "            name_img = os.path.join(query_path, img_name)\n",
    "            image = Image.open(name_img).convert('RGB')  # 读取图片并转换为RGB格式\n",
    "            image = transform(image).unsqueeze(0).to(device)  # 预处理并转移到设备\n",
    "\n",
    "            with torch.no_grad():\n",
    "                features = model(image)  # 获取图片特征\n",
    "                # 计算与各类别原型向量的相似度\n",
    "                similarities = {label: F.cosine_similarity(features, prototype.unsqueeze(0), dim=1).item()\n",
    "                                for label, prototype in prototypes.items()}\n",
    "                pred_class = max(similarities, key=similarities.get)  # 找到相似度最大的类别\n",
    "                res.append(f'{img_name},{pred_class}')  # 保存结果\n",
    "\n",
    "    # 将预测结果保存到result_save_path\n",
    "    with open(result_save_path, 'w') as f:\n",
    "        f.write('\\n'.join(res))\n",
    "\n",
    "    # 使用 Pandas 交换列的位置\n",
    "    result_df = pd.read_csv(result_save_path)\n",
    "    result_df = result_df[['label', 'img_name']]  # 交换列的位置\n",
    "    result_df.to_csv(result_save_path, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ！！！以下内容不允许修改，修改会导致评分出错\n",
    "    to_pred_dir = r'last\\shetai\\image'  # 所需预测的文件夹路径\n",
    "    result_save_path = r'last\\shetai\\jg.csv'  # 预测结果保存文件路径，已指定格式为csv\n",
    "    main(to_pred_dir, result_save_path)  # 调用主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "20\n",
      "708\n",
      "4\n",
      "697\n",
      "4\n",
      "20\n",
      "4\n",
      "155\n",
      "4\n",
      "247\n",
      "4\n",
      "20\n",
      "4\n",
      "155\n",
      "20\n",
      "4\n",
      "146\n",
      "708\n",
      "708\n",
      "697\n",
      "708\n",
      "708\n",
      "4\n",
      "697\n",
      "697\n",
      "547\n",
      "4\n",
      "155\n",
      "547\n",
      "4\n",
      "697\n",
      "146\n",
      "697\n",
      "646\n",
      "547\n",
      "708\n",
      "146\n",
      "146\n",
      "155\n",
      "146\n",
      "4\n",
      "4\n",
      "4\n",
      "708\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "708\n",
      "4\n",
      "708\n",
      "697\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "697\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "247\n",
      "547\n",
      "4\n",
      "708\n",
      "646\n",
      "697\n",
      "4\n",
      "4\n",
      "20\n",
      "4\n",
      "4\n",
      "697\n",
      "697\n",
      "697\n",
      "416\n",
      "4\n",
      "155\n",
      "697\n",
      "697\n",
      "4\n",
      "146\n",
      "4\n",
      "697\n",
      "697\n",
      "4\n",
      "247\n",
      "4\n",
      "697\n",
      "708\n",
      "4\n",
      "416\n",
      "416\n",
      "4\n",
      "697\n",
      "697\n",
      "4\n",
      "20\n",
      "697\n",
      "4\n",
      "4\n",
      "708\n",
      "697\n",
      "20\n",
      "4\n",
      "4\n",
      "247\n",
      "708\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:\\\\Work\\\\wen_jian\\\\chinese_machine\\\\last (6)\\\\last\\\\shetai\\\\jg.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m to_pred_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWork\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwen_jian\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m中医药\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmed_web\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mshetai\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtask1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMirror-Approximated\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 所需预测的文件夹路径\u001b[39;00m\n\u001b[0;32m    105\u001b[0m result_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWork\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwen_jian\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchinese_machine\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlast (6)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mshetai\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 预测结果保存文件路径，已指定格式为csv\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_pred_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_save_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 调用主函数\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 93\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(to_pred_dir, result_save_path)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28mprint\u001b[39m(pred_class)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# 将预测结果保存到result_save_path\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     94\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(res))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# 使用 Pandas 交换列的位置\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\python3.11\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:\\\\Work\\\\wen_jian\\\\chinese_machine\\\\last (6)\\\\last\\\\shetai\\\\jg.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 构建改进后的CNN模型\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # 定义卷积层和批量归一化层\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 定义池化层\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # 全连接层\n",
    "        self.fc2 = nn.Linear(1024, 256)  # 全连接层\n",
    "        self.fc3 = nn.Linear(256, num_classes)  # 输出层，num_classes为类别数\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout层，用于防止过拟合\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # 第一个卷积层\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # 第二个卷积层\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # 第三个卷积层\n",
    "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))  # 第四个卷积层\n",
    "        x = x.view(-1, 512 * 14 * 14)  # 展平操作\n",
    "        x = torch.relu(self.fc1(x))  # 第一个全连接层\n",
    "        x = self.dropout(x)  # Dropout层\n",
    "        x = torch.relu(self.fc2(x))  # 第二个全连接层\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "\n",
    "# 判断文件是否有效\n",
    "def is_valid_file(filename):\n",
    "    # 过滤掉以点开头的文件（如隐藏文件）和 .DS_Store 文件\n",
    "    return not filename.startswith('.') and filename != '.DS_Store'\n",
    "\n",
    "\n",
    "# 以下为逻辑函数, main函数的入参和最终的结果输出不可修改\n",
    "def main(to_pred_dir, result_save_path):\n",
    "    model_dir = r''\n",
    "\n",
    "    # 实例化模型并加载已保存的模型\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 动态选择使用 GPU 或 CPU\n",
    "    num_classes = 762  # 根据检查点的类别数进行修改\n",
    "    model = CNNModel(num_classes=num_classes).to(device)  # 创建模型实例\n",
    "\n",
    "    # 加载模型参数，允许部分加载\n",
    "    checkpoint = torch.load(os.path.join(model_dir, 'my_pytorch_model.pth'), map_location=device)\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "\n",
    "    # 图片预处理（与训练时保持一致）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图片大小\n",
    "        transforms.ToTensor(),  # 转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "    ])\n",
    "\n",
    "    if not os.path.exists(to_pred_dir):\n",
    "        print(f\"Error: Directory {to_pred_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # 获取目录下的所有有效图片文件\n",
    "    image_files = [f for f in os.listdir(to_pred_dir) if is_valid_file(f) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    res = ['img_name,label']  # 初始化结果文件，定义表头\n",
    "\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(to_pred_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # 读取图片并转换为RGB格式\n",
    "        image = transform(image).unsqueeze(0).to(device)  # 预处理并转移到设备\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred_class = predicted.item()\n",
    "            res.append(f'{img_name},{pred_class}')  # 保存结果\n",
    "            print(pred_class)\n",
    "    # 将预测结果保存到result_save_path\n",
    "    with open(result_save_path, 'w') as f:\n",
    "        f.write('\\n'.join(res))\n",
    "\n",
    "    # 使用 Pandas 交换列的位置\n",
    "    result_df = pd.read_csv(result_save_path)\n",
    "    result_df = result_df[['label', 'img_name']]  # 交换列的位置\n",
    "    result_df.to_csv(result_save_path, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ！！！以下内容不允许修改，修改会导致评分出错\n",
    "    to_pred_dir = r'D:\\Work\\wen_jian\\中医药\\med_web\\last\\shetai\\task1\\support\\Mirror-Approximated'  # 所需预测的文件夹路径\n",
    "    result_save_path = r\"D:\\Work\\wen_jian\\chinese_machine\\last (6)\\last\\shetai\\jg.csv\"  # 预测结果保存文件路径，已指定格式为csv\n",
    "    main(to_pred_dir, result_save_path)  # 调用主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18089\\AppData\\Local\\Temp\\ipykernel_15352\\580647341.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(model_dir, 'my_pytorch_model.pth'), map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 构建改进后的CNN模型\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # 定义卷积层和批量归一化层\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 定义池化层\n",
    "        self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # 全连接层\n",
    "        self.fc2 = nn.Linear(1024, 256)  # 全连接层\n",
    "        self.fc3 = nn.Linear(256, num_classes)  # 输出层，num_classes为类别数\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout层，用于防止过拟合\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # 第一个卷积层\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # 第二个卷积层\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # 第三个卷积层\n",
    "        x = self.pool(torch.relu(self.bn4(self.conv4(x))))  # 第四个卷积层\n",
    "        x = x.view(-1, 512 * 14 * 14)  # 展平操作\n",
    "        x = torch.relu(self.fc1(x))  # 第一个全连接层\n",
    "        x = self.dropout(x)  # Dropout层\n",
    "        x = torch.relu(self.fc2(x))  # 第二个全连接层\n",
    "        x = self.fc3(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "\n",
    "# 判断文件是否有效\n",
    "def is_valid_file(filename):\n",
    "    # 过滤掉以点开头的文件（如隐藏文件）和 .DS_Store 文件\n",
    "    return not filename.startswith('.') and filename != '.DS_Store'\n",
    "\n",
    "\n",
    "# 以下为逻辑函数, main函数的入参和最终的结果输出不可修改\n",
    "def main(to_pred_dir, result_save_path):\n",
    "    model_dir = r'shetai'\n",
    "\n",
    "    # 实例化模型并加载已保存的模型\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 动态选择使用 GPU 或 CPU\n",
    "    num_classes = 762  # 根据检查点的类别数进行修改\n",
    "    model = CNNModel(num_classes=num_classes).to(device)  # 创建模型实例\n",
    "\n",
    "    # 加载模型参数，允许部分加载\n",
    "    checkpoint = torch.load(os.path.join(model_dir, 'my_pytorch_model.pth'), map_location=device)\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "\n",
    "    # 图片预处理（与训练时保持一致）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图片大小\n",
    "        transforms.ToTensor(),  # 转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "    ])\n",
    "\n",
    "    task1_support_path = os.path.join(to_pred_dir, 'task1\\support')\n",
    "    if not os.path.exists(task1_support_path):\n",
    "        print(f\"Error: Directory {task1_support_path} does not exist.\")\n",
    "        return\n",
    "\n",
    "    prototypes = {}  # 存储各类别的原型向量\n",
    "    for class_name in os.listdir(task1_support_path):  # 加载支持集并计算原型向量\n",
    "        if class_name == '.DS_Store':\n",
    "            continue\n",
    "        class_folder = os.path.join(task1_support_path, class_name)\n",
    "        if not os.path.isdir(class_folder):\n",
    "            continue\n",
    "\n",
    "        class_features_list = []  # 存储当前类别的特征\n",
    "        for img_name in os.listdir(class_folder):  # 遍历每个类别中的图片\n",
    "            if img_name.startswith('.') or img_name == '.DS_Store':\n",
    "                continue\n",
    "            img_path = os.path.join(class_folder, img_name)\n",
    "            image = Image.open(img_path).convert('RGB')  # 读取图片并转换为RGB格式\n",
    "            image = transform(image).unsqueeze(0).to(device)  # 预处理并转移到设备\n",
    "\n",
    "            with torch.no_grad():\n",
    "                features = model(image)  # 获取图片特征\n",
    "                class_features_list.append(features)\n",
    "\n",
    "        if class_features_list:  # 计算该类别的原型向量（特征均值）\n",
    "            class_features = torch.cat(class_features_list, dim=0)\n",
    "            prototypes[class_name] = class_features.mean(dim=0)\n",
    "\n",
    "    if not os.path.exists(to_pred_dir):\n",
    "        print(f\"Error: Directory {to_pred_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # 获取目录下的所有有效图片文件\n",
    "    image_files = [f for f in os.listdir(to_pred_dir) if is_valid_file(f) and f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    res = ['img_name,label']  # 初始化结果文件，定义表头\n",
    "\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(to_pred_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # 读取图片并转换为RGB格式\n",
    "        image = transform(image).unsqueeze(0).to(device)  # 预处理并转移到设备\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(image)  # 获取图片特征\n",
    "            # 计算与各类别原型向量的相似度\n",
    "            similarities = {label: F.cosine_similarity(features, prototype.unsqueeze(0), dim=1).item()\n",
    "                            for label, prototype in prototypes.items()}\n",
    "            pred_class = max(similarities, key=similarities.get)  # 找到相似度最大的类别\n",
    "            res.append(f'{img_name},{pred_class}')  # 保存结果\n",
    "\n",
    "    # 将预测结果保存到result_save_path\n",
    "    with open(result_save_path, 'w') as f:\n",
    "        f.write('\\n'.join(res))\n",
    "\n",
    "    # 使用 Pandas 交换列的位置\n",
    "    result_df = pd.read_csv(result_save_path)\n",
    "    result_df = result_df[['label', 'img_name']]  # 交换列的位置\n",
    "    result_df.to_csv(result_save_path, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ！！！以下内容不允许修改，修改会导致评分出错\n",
    "    to_pred_dir = r'last\\shetai'  # 所需预测的文件夹路径\n",
    "    result_save_path = r'last\\shetai\\jg.csv'  # 预测结果保存文件路径，已指定格式为csv\n",
    "    main(to_pred_dir, result_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "def load_model(model_path, num_classes=762):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 构建改进后的CNN模型\n",
    "    class CNNModel(nn.Module):\n",
    "        def __init__(self, num_classes):\n",
    "            super(CNNModel, self).__init__()\n",
    "            # 定义卷积层和批量归一化层\n",
    "            self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(128)\n",
    "            self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(256)\n",
    "            self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "            self.bn4 = nn.BatchNorm2d(512)\n",
    "            self.pool = nn.MaxPool2d(2, 2)  # 定义池化层\n",
    "            self.fc1 = nn.Linear(512 * 14 * 14, 1024)  # 全连接层\n",
    "            self.fc2 = nn.Linear(1024, 256)  # 全连接层\n",
    "            self.fc3 = nn.Linear(256, num_classes)  # 输出层，num_classes为类别数\n",
    "            self.dropout = nn.Dropout(0.5)  # Dropout层，用于防止过拟合\n",
    "\n",
    "        def forward(self, x):\n",
    "            # 前向传播函数\n",
    "            x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # 第一个卷积层\n",
    "            x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # 第二个卷积层\n",
    "            x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # 第三个卷积层\n",
    "            x = self.pool(torch.relu(self.bn4(self.conv4(x))))  # 第四个卷积层\n",
    "            x = x.view(-1, 512 * 14 * 14)  # 展平操作\n",
    "            x = torch.relu(self.fc1(x))  # 第一个全连接层\n",
    "            x = self.dropout(x)  # Dropout层\n",
    "            x = torch.relu(self.fc2(x))  # 第二个全连接层\n",
    "            x = self.fc3(x)  # 输出层\n",
    "            return x\n",
    "\n",
    "\n",
    "    # 加载模型\n",
    "    model = CNNModel(num_classes).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    return model, device\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 调整图片大小\n",
    "        transforms.ToTensor(),  # 转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "    ])\n",
    "\n",
    "# 预测函数\n",
    "def predict_image(image_path, model, device, prototypes):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 预处理\n",
    "    with torch.no_grad():\n",
    "        features = model(image)  # 提取特征\n",
    "        # 计算与各类别原型向量的相似度\n",
    "        similarities = {\n",
    "            label: torch.cosine_similarity(features, proto.unsqueeze(0), dim=1).item()\n",
    "            for label, proto in prototypes.items()\n",
    "        }\n",
    "    return max(similarities, key=similarities.get)  # 返回最相似的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNNModel:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([5, 256]) from checkpoint, the shape in current model is torch.Size([762, 256]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([762]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m support_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask1/support\u001b[39m\u001b[38;5;124m\"\u001b[39m        \u001b[38;5;66;03m# 确保路径正确\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m model, device \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m762\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 计算原型向量\u001b[39;00m\n\u001b[0;32m     26\u001b[0m prototypes \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[1], line 44\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_path, num_classes)\u001b[0m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m CNNModel(num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, device\n",
      "File \u001b[1;32md:\\Work\\python3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2577\u001b[0m             ),\n\u001b[0;32m   2578\u001b[0m         )\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2584\u001b[0m         )\n\u001b[0;32m   2585\u001b[0m     )\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNModel:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([5, 256]) from checkpoint, the shape in current model is torch.Size([762, 256]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([762])."
     ]
    }
   ],
   "source": [
    "from django.http import JsonResponse, HttpResponse\n",
    "import json\n",
    "from django.urls import reverse\n",
    "from django.views.decorators.csrf import csrf_exempt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from django.shortcuts import render, redirect\n",
    "from django.core.files.base import ContentFile\n",
    "import os\n",
    "from django.conf import settings\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "model_path = \"my_pytorch_model.pth\"  # 确保路径正确\n",
    "support_dir = \"task1/support\"        # 确保路径正确\n",
    "\n",
    "# 加载模型\n",
    "model, device = load_model(model_path,num_classes=762)\n",
    "\n",
    "# 计算原型向量\n",
    "prototypes = {}\n",
    "for class_name in os.listdir(support_dir):\n",
    "    if class_name == '.DS_Store':\n",
    "        continue\n",
    "    class_folder = os.path.join(support_dir, class_name)\n",
    "    if not os.path.isdir(class_folder):\n",
    "        continue\n",
    "\n",
    "    class_features_list = []\n",
    "    for img_name in os.listdir(class_folder):\n",
    "        if img_name.startswith('.') or img_name == '.DS_Store':\n",
    "            continue\n",
    "        img_path = os.path.join(class_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(image)\n",
    "            class_features_list.append(features)\n",
    "\n",
    "    if class_features_list:\n",
    "        class_features = torch.cat(class_features_list, dim=0)\n",
    "        prototypes[class_name] = class_features.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Grey-Black', 'Mirror-Approximated', 'Thin-White', 'White-Greasy', 'Yellow-Greasy'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 保存到文件\n",
    "torch.save(prototypes, \"prototypes.pt\")\n",
    "\n",
    "# 之后可以加载\n",
    "loaded_prototypes = torch.load(\"prototypes.pt\")\n",
    "print(loaded_prototypes.keys())  # 查看所有类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNNModel:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([5, 256]) from checkpoint, the shape in current model is torch.Size([762, 256]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([762]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_pytorch_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m prototypes_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprototypes.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 你保存的原型向量文件\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m model, device \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m762\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 加载模型和原型向量\u001b[39;00m\n\u001b[0;32m     25\u001b[0m prototypes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(prototypes_path, map_location\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# 直接加载\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 44\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_path, num_classes)\u001b[0m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m CNNModel(num_classes)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, device\n",
      "File \u001b[1;32md:\\Work\\python3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2577\u001b[0m             ),\n\u001b[0;32m   2578\u001b[0m         )\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2584\u001b[0m         )\n\u001b[0;32m   2585\u001b[0m     )\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNNModel:\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([5, 256]) from checkpoint, the shape in current model is torch.Size([762, 256]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([762])."
     ]
    }
   ],
   "source": [
    "from django.http import JsonResponse, HttpResponse\n",
    "import json\n",
    "from django.urls import reverse\n",
    "from django.views.decorators.csrf import csrf_exempt\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from django.shortcuts import render, redirect\n",
    "from django.core.files.base import ContentFile\n",
    "import os\n",
    "from django.conf import settings\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化\n",
    "model_path = \"my_pytorch_model.pth\"\n",
    "prototypes_path = \"prototypes.pt\"  # 你保存的原型向量文件\n",
    "model, device = load_model(model_path,num_classes=762)\n",
    "# 加载模型和原型向量\n",
    "\n",
    "prototypes = torch.load(prototypes_path, map_location=device)  # 直接加载\n",
    "\n",
    "# 预测新图像\n",
    "result = predict_image(r\"D:\\Work\\wen_jian\\中医药\\med_web\\last\\shetai\\task1\\support\\White-Greasy\\White-Greasy_646.jpg\", model, device, prototypes)\n",
    "print(f\"预测结果: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
